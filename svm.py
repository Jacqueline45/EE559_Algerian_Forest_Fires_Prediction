
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kiMsqySfGDnmDK-FKA9peetZ4GhD4Hpa
"""

!unzip /content/EE559_Project-main.zip

import pandas as pd 
import imblearn
import numpy as np 

from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from imblearn.over_sampling import SMOTE

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Generates all performance measures

def metrics(true_labels, pred_labels, plot_title, work='test'):
    cf_matrix = confusion_matrix(true_labels, pred_labels)
    TP, TN, FP, FN = cf_matrix[1][1], cf_matrix[0][0], cf_matrix[0][1], cf_matrix[1][0]
    Recall = TP/(TP+FN)
    Precision = TP/(TP+FP)
    F1_score = 2*Recall*Precision/(Recall+Precision)
    Accuracy = (TP+TN)/true_labels.shape[0]
    
    if work == 'test':
        ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

        ax.set_title(plot_title)
        ax.set_xlabel('Predicted Values')
        ax.set_ylabel('Actual Values ')

        ax.xaxis.set_ticklabels(['0','1'])
        ax.yaxis.set_ticklabels(['0','1'])



        return F1_score, Accuracy

    else:
        return F1_score, Accuracy, TP, TN, FP, FN

def plot_val_cf_matrix(true_labels, pred_labels, plot_title, TP, TN, FP, FN):
    cf_matrix = confusion_matrix(true_labels, pred_labels)
    cf_matrix[1][1], cf_matrix[0][0], cf_matrix[0][1], cf_matrix[1][0] = TP, TN, FP, FN
    
    ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

    ax.set_title(plot_title)
    ax.set_xlabel('Predicted Values')
    ax.set_ylabel('Actual Values ')

    ## Ticket labels - List must be in alphabetical order
    ax.xaxis.set_ticklabels(['0','1'])
    ax.yaxis.set_ticklabels(['0','1'])

    # plt.savefig('cf_matrix_plots/'+plot_title+'_val.png')

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

fires_train = pd.read_csv("/content/EE559_Project-main/datasets/algerian_fires_train.csv")
fires_test = pd.read_csv("/content/EE559_Project-main/datasets/algerian_fires_test.csv")

data = fires_train.describe()
tstdata = fires_test.describe()

fires_train = fires_train.iloc[:,1:]
fires_test = fires_test.iloc[:,1:]


##Normalising the data as there is scale difference
predictors = fires_train.iloc[:,:-1]
target = fires_train.iloc[:,-1:]

predictorstst = fires_test.iloc[:,:-1]
targettst = fires_test.iloc[:,-1:]

scalar = MinMaxScaler()

fires = scalar.fit_transform(predictors)
firestst = scalar.fit_transform(predictorstst)

x_train,x_test,y_train,y_test = train_test_split(predictors,target, stratify = target)

X_train,X_test,Y_train,Y_test = train_test_split(predictorstst,targettst, stratify = targettst)


model_linear = SVC(kernel = "linear")
model_linear.fit(x_train,y_train)
pred_test_linear = model_linear.predict(x_test)

#test

model_linear1 = SVC(kernel = "linear")
model_linear1.fit(X_train,Y_train)
pred_test_linear1 = model_linear1.predict(X_test)

# kernel = rbf
model_rbf = SVC(kernel = "rbf")
model_rbf.fit(x_train,y_train)
pred_test_rbf = model_rbf.predict(x_test)

#test rbf
model_rbf1 = SVC(kernel = "rbf")
model_rbf1.fit(x_train,y_train)
pred_test_rbf1 = model_rbf1.predict(X_test)

from sklearn.metrics import accuracy_score
p = accuracy_score(y_test,pred_test_linear)
q = accuracy_score(y_test,pred_test_rbf)
r = accuracy_score(Y_test,pred_test_linear1)
s = accuracy_score(Y_test,pred_test_rbf1)

print("Train Linear Accuracy=", p, "Train RBF Accuracy=", q, "Test Linear Accuracy=", r, "Test RBF Accuracy=", s)

F1_score, Accuracy = metrics(y_test, pred_test_linear, "Training and Validation Set")
print("Train F1_score=", F1_score, "Train Accuracy=", Accuracy)

F1_score, Accuracy = metrics(y_test, pred_test_rbf, "Training and Validation Set RBF")
print("Train RBF F1_score=", F1_score, "Train RBF Accuracy=", Accuracy)

F1_score, Accuracy = metrics(Y_test, pred_test_linear1, "Test Set")
print("Test F1_score=", F1_score, "Test Accuracy=", Accuracy)

F1_score, Accuracy = metrics(Y_test, pred_test_rbf1, "Test Set RBF")
print("Test RBF F1_score=", F1_score, "Test RBF Accuracy=", Accuracy)